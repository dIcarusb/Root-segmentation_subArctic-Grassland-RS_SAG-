{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1eb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import cv2\n",
    "import os\n",
    "from skimage import img_as_bool, io, color, morphology\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac3b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(d):\n",
    "    a=d-d.min()\n",
    "    b=d.max()-d.min()\n",
    "    return np.divide(a, b, dtype=\"float32\")#,out=np.zeros_like(a), where=b!=0)\n",
    "\n",
    "def transcal(d):\n",
    "    d = d.transpose(0,3,1,2)\n",
    "    return scaled(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49be6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_reference(input_img, ref_img):\n",
    "    # Get the minimum and maximum pixel values of the reference image\n",
    "    ref_min = np.min(ref_img)\n",
    "    ref_max = np.max(ref_img)\n",
    "\n",
    "    # Get the minimum and maximum pixel values of the input image\n",
    "    input_min = np.min(input_img)\n",
    "    input_max = np.max(input_img)\n",
    "\n",
    "    # Compute the scaling factors for the input image\n",
    "    scale_min = (ref_min / input_min) if input_min > 0 else 1\n",
    "    scale_max = ref_max / input_max\n",
    "\n",
    "    # Apply the scaling factors to the input image\n",
    "    normalized_img = input_img * scale_min\n",
    "    normalized_img = np.where(normalized_img > ref_max, ref_max, normalized_img)\n",
    "    \n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fa59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_denoizer(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    A = cv2.fastNlMeansDenoising(a, None, 4, 7, 21)\n",
    "    B = cv2.fastNlMeansDenoising(b, None, 4, 7, 21)\n",
    "    filtered = cv2.fastNlMeansDenoising(l, None, 6, 7, 10)\n",
    "    #noise = cv2.absdiff(l, filtered)\n",
    "    #L = cv2.absdiff(l, noise)\n",
    "    new=cv2.merge((filtered,A,B))\n",
    "    new= cv2.cvtColor(new, cv2.COLOR_LAB2BGR)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fe1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def im_hist_norm(src, ref_img):\n",
    "    multi = True if src.shape[-1] > 1 else False\n",
    "    matched = exposure.match_histograms(src, ref_img, multichannel=multi)\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38786a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_overexposure(imag, channel=\"green\", target_value=210):\n",
    "    # Get the channel index\n",
    "    channel_idx = {'blue': 0, 'green': 1, 'red': 2}[channel.lower()]\n",
    "\n",
    "    # Split the image channels\n",
    "    #b, g, r = cv2.split(imag)\n",
    "\n",
    "    # Threshold the selected channel to identify overexposed pixels\n",
    "    overexposed_pixels = imag[:,:,channel_idx] > target_value\n",
    "\n",
    "    # Replace the overexposed pixels with the target value\n",
    "    imag[:,:,channel_idx][overexposed_pixels] = target_value\n",
    "\n",
    "    # Merge the channels back into a single image\n",
    "    #normalized_img = cv2.merge([b, g, r])\n",
    "\n",
    "    return imag #normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a6678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rootlen(r,mmcoef_=1, intercept=0):\n",
    "    a = [] # list of lengths \n",
    "    for i in range(r.shape[0]):\n",
    "        image = np.round(r[i,0,:,:],decimals=0) #y[i,0,:,:]\n",
    "        #image = cv2.resize(image,(256,256))\n",
    "        image = img_as_bool(image)\n",
    "        image = ndimage.binary_closing(image, structure=np.ones((3,3)))\n",
    "        skeleton = morphology.medial_axis(image)\n",
    "        sk = np.round(skeleton.sum(), decimals=1)\n",
    "        ## Correction\n",
    "        sk = np.round(sk*mmcoef_)+intercept\n",
    "        #print(sk)\n",
    "        a.append(sk)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6afc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(r,mmcoef_=1, intercept=0):\n",
    "    a = [] # list of lengths \n",
    "    for i in range(r.shape[0]):\n",
    "        image = np.round(r[i,0,:,:],decimals=0) #y[i,0,:,:]\n",
    "        #image = cv2.resize(image,(256,256))\n",
    "        image = img_as_bool(image)\n",
    "        image = ndimage.binary_closing(image, structure=np.ones((3,3)))\n",
    "        \n",
    "        sk = np.round(image.sum(), decimals=1)\n",
    "        ## Correction\n",
    "        sk = np.round(sk*mmcoef_)+intercept\n",
    "        #print(sk)\n",
    "        a.append(sk)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5fd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(Model,dat):\n",
    "    out=torch.tensor([])\n",
    "    for i in range(0,dat.shape[0],1):\n",
    "        torch.cuda.empty_cache() \n",
    "        j=i+1\n",
    "        #print(j)\n",
    "        if j==(dat.shape[0]+1):\n",
    "            print(j)\n",
    "            with torch.no_grad():\n",
    "                outputs = Model(torch.from_numpy(dat[i:]).cuda()) \n",
    "            out = torch.cat((out,outputs.cpu()),0)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = Model(torch.from_numpy(dat[i:j]).cuda()) \n",
    "            out = torch.cat((out,outputs.cpu()),0)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bd4226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Image_processing\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] The specified module could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./BipEModel_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52345429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"./BipEModel3.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c562eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir=\"D:/Imaging_PY/Experiments/Biplabi_images/GO_TUBES/\"\n",
    "tubes = os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b771847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference building...\n",
      "2020.05.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Image_processing\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: `multichannel` is a deprecated argument name for `match_histograms`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting masks...\n",
      "2020.06.24\n",
      "predicting masks...\n",
      "2020.07.16\n",
      "predicting masks...\n",
      "2020.08.12\n",
      "predicting masks...\n",
      "2020.09.22\n",
      "predicting masks...\n",
      "2020.10.08\n",
      "predicting masks...\n",
      "2020.12.20\n",
      "predicting masks...\n",
      "2021.03.24\n",
      "predicting masks...\n",
      "2021.04.20\n",
      "predicting masks...\n",
      "2021.06.17\n",
      "predicting masks...\n",
      "2021.07.14\n",
      "predicting masks...\n",
      "2021.08.03\n",
      "predicting masks...\n",
      "2021.12.23\n",
      "predicting masks...\n",
      "2022.04.13\n",
      "predicting masks...\n",
      "2022.06.20\n",
      "predicting masks...\n",
      "2022.08.19\n",
      "predicting masks...\n",
      "GO-Tube 23\n"
     ]
    }
   ],
   "source": [
    "for tube in tubes:\n",
    "    file_count = 0\n",
    "    for _, _, files in os.walk(main_dir+tube+\"/\"):\n",
    "        file_count += len(files)\n",
    "    if file_count == 416:\n",
    "        dir0 = main_dir+tube+\"/\"\n",
    "        l = os.listdir(dir0)\n",
    "        date_pattern = r\"\\d{4}\\.\\d{2}\\.\\d{2}\"  # Regular expression pattern for date in format YYYY.MM.DD\n",
    "        unique_dates = set()\n",
    "\n",
    "        for file_name in l:\n",
    "            match = re.search(date_pattern, file_name)\n",
    "            if match:\n",
    "                date = match.group()\n",
    "                unique_dates.add(date)\n",
    "\n",
    "        dates_list = list(unique_dates)\n",
    "        dates_list = sorted(dates_list)\n",
    "        # reference building\n",
    "        print(\"reference building...\")\n",
    "        pattern = r\"_L(\\d{3})\"\n",
    "        ref={}\n",
    "        try:\n",
    "            for file_name in l:\n",
    "                if dates_list[2] in file_name:\n",
    "                    match = re.search(pattern, file_name)\n",
    "                    #print(match)\n",
    "                    img = cv2.imread(dir0+file_name)\n",
    "                    img = lab_denoizer(np.flip(img,2))\n",
    "                    img = cv2.resize(img, (640, 480))\n",
    "                    location = match.group(1)\n",
    "                    ref[location] = img\n",
    "        except:\n",
    "            print(tube+\" is wrong\")\n",
    "\n",
    "\n",
    "        date_counts = {}\n",
    "        pattern = r\"_L(\\d{3})\"\n",
    "        for date in dates_list:\n",
    "            print(date)\n",
    "            # building datset with same date\n",
    "            X = np.zeros(shape=(1,480,640,3), dtype=\"uint8\") #shape=(1,480,640,3)\n",
    "            Grays = np.zeros(shape=(1,480,640,1), dtype=\"uint8\")\n",
    "            for file_name in l:\n",
    "                if date in file_name:\n",
    "                    match = re.search(pattern, file_name)\n",
    "                    location = match.group(1)\n",
    "                    img = cv2.imread(dir0+file_name)\n",
    "                    img = lab_denoizer(np.flip(img,2))\n",
    "                    img = cv2.resize(img, (640, 480))\n",
    "                    im = im_hist_norm(img, ref[location])\n",
    "                    # normalization\n",
    "                    correct = correct_overexposure(im,\"green\",target_value=210)\n",
    "                    correct = correct_overexposure(correct,\"blue\",target_value=210)\n",
    "                    correct = correct_overexposure(correct,\"red\",target_value=210)\n",
    "                    X = np.append(X, [correct], axis=0)\n",
    "                    # gray   \n",
    "                    gray = cv2.cvtColor(correct, cv2.COLOR_BGR2GRAY)\n",
    "                    gray = np.expand_dims(gray, axis=2)\n",
    "                    Grays = np.append(Grays, [gray], axis=0)\n",
    "                    \n",
    "                    \n",
    "\n",
    "            X = X[1:]\n",
    "            Grays = Grays[1:]\n",
    "            X_test = transcal(X)\n",
    "            G_test = transcal(Grays)\n",
    "\n",
    "            # prediction of masks\n",
    "            print(\"predicting masks...\")\n",
    "            out1 = predict_mask(model1,X_test)\n",
    "            out2 = predict_mask(model, G_test)\n",
    "            out3 = scaled(out1+out2)\n",
    "            out3 = (out3>0.3).astype(\"float32\")\n",
    "\n",
    "            # claculate lengths and add to date_counts dictionary\n",
    "            total_lengths=calculate_rootlen(out3)  \n",
    "            total_area = calculate_area(out3)\n",
    "            date_counts[date] = [total_lengths,total_area]\n",
    "\n",
    "        lengths = {}\n",
    "        areas = {}\n",
    "\n",
    "        for key, value in date_counts.items():\n",
    "            list1, list2 = value\n",
    "            lengths[key] = list1\n",
    "            areas[key] = list2\n",
    "\n",
    "        L = pd.DataFrame.from_dict(lengths)\n",
    "        A = pd.DataFrame.from_dict(areas)\n",
    "\n",
    "        L.to_csv(tube+\"_length.csv\")\n",
    "        A.to_csv(tube+\"_areas.csv\")\n",
    "        print(tube)\n",
    "    else:\n",
    "        print(tube+\" different number of pictures\")\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330309e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.05.26\n",
      "2020.06.25\n",
      "2020.07.17\n",
      "2020.08.12\n",
      "2020.09.18\n",
      "2020.10.07\n",
      "2020.11.24\n",
      "2021.03.12\n",
      "2021.04.18\n",
      "2021.06.20\n",
      "2021.07.13\n",
      "2021.08.02\n",
      "2022.01.13\n",
      "2022.04.11\n",
      "2022.06.16\n",
      "2022.08.18\n"
     ]
    }
   ],
   "source": [
    "for date in dates_list:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ac30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0 = main_dir+\"GO-Tube 19\"+\"/\"\n",
    "l = os.listdir(dir0)\n",
    "date_pattern = r\"\\d{4}\\.\\d{2}\\.\\d{2}\"  # Regular expression pattern for date in format YYYY.MM.DD\n",
    "unique_dates = set()\n",
    "for file_name in l:\n",
    "            match = re.search(date_pattern, file_name)\n",
    "            if match:\n",
    "                date = match.group()\n",
    "                unique_dates.add(date)\n",
    "dates_list = list(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83389662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020.05.30',\n",
       " '2020.06.24',\n",
       " '2020.07.17',\n",
       " '2020.08.12',\n",
       " '2020.09.22',\n",
       " '2020.10.08',\n",
       " '2020.12.20',\n",
       " '2021.03.24',\n",
       " '2021.04.20',\n",
       " '2021.06.17',\n",
       " '2021.07.14',\n",
       " '2021.08.03',\n",
       " '2021.12.23',\n",
       " '2022.04.12',\n",
       " '2022.06.20',\n",
       " '2022.08.19']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf9d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in GO-Tube 19: 416\n",
      "Number of files in GO-tube 20: 416\n",
      "Number of files in GO-Tube 21: 416\n",
      "Number of files in GO-Tube 22: 416\n",
      "Number of files in GO-Tube 23: 289\n",
      "Number of files in GO-Tube 24: 416\n",
      "Number of files in GO-Tube 25: 416\n",
      "Number of files in GO-Tube 26: 390\n",
      "Number of files in GO-Tube 27: 416\n",
      "Number of files in GO-Tube 28: 416\n",
      "Number of files in GO-Tube 29: 416\n",
      "Number of files in GO-Tube 30: 416\n",
      "Number of files in GO-Tube 31: 416\n",
      "Number of files in GO-Tube 32: 416\n",
      "Number of files in GO-Tube 33: 416\n",
      "Number of files in GO-Tube 34: 416\n",
      "Number of files in GO-Tube 35: 416\n",
      "Number of files in GO-Tube 36: 416\n",
      "Number of files in GO-Tube 37: 416\n",
      "Number of files in GO-Tube 38: 416\n",
      "Number of files in GO-Tube 39: 390\n",
      "Number of files in GO-Tube 40: 416\n",
      "Number of files in GO-Tube 41: 416\n",
      "Number of files in GO-Tube 42: 416\n",
      "Number of files in GO-Tube 43: 416\n",
      "Number of files in GO-Tube 44: 416\n",
      "Number of files in GO-Tube 45: 416\n",
      "Number of files in GO-Tube 46: 416\n",
      "Number of files in GO-Tube 47: 416\n",
      "Number of files in GO-Tube 48: 416\n"
     ]
    }
   ],
   "source": [
    "for tube in tubes:\n",
    "    file_count = 0\n",
    "    for _, _, files in os.walk(main_dir+tube+\"/\"):\n",
    "        file_count += len(files)\n",
    "    print(f\"Number of files in {tube}: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c42e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
